{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import API keys\n",
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "# Load environment variables from a.env file\n",
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "openai_api_key = os.environ[\"OPENAI_API_KEY\"]\n",
    "\n",
    "# Load opensource api models\n",
    "groql_api_key = os.environ[\"GROQ_API_KEY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import Groq chat model\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "\n",
    "llamaChatModel = ChatGroq(\n",
    "    model=\"llama3-70b-8192\"\n",
    ")\n",
    "\n",
    "chain = RunnablePassthrough()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_template(\"tell me something curious about a {soccer_player}\")\n",
    "\n",
    "output_parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Here\\'s something curious about Kylian Mbappé:\\n\\n**Did you know that Kylian Mbappé is a huge fan of basketball and has a special bond with NBA legend LeBron James?**\\n\\nIn fact, Mbappé has often spoken about how he draws inspiration from James\\' work ethic, dedication, and philanthropic efforts. The two have exchanged jerseys and have been spotted together at various sporting events.\\n\\nWhat\\'s even more fascinating is that Mbappé has been known to incorporate some basketball-inspired moves into his soccer games. He has been seen performing \"crossover\" style dribbles, similar to those used in basketball, to beat opponents on the pitch!\\n\\nThis unique connection between two of the world\\'s top athletes from different sports is certainly an interesting curiosity about Mbappé\\'s personality and interests outside of soccer.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Invoke the chains\n",
    "chain = prompt | llamaChatModel | output_parser\n",
    "\n",
    "chain.invoke({\"soccer_player\" : \"Mbappe\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### .bind() Runnables Function\n",
    "* To add arguments to a Runnable functionin aLCEL chain\n",
    "* For example, we can add an argument to stop the model response when it reaches the word \"Ronaldo\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Here's something curious about Cristiano \""
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = prompt | llamaChatModel.bind(stop=[\"Ronaldo\"]) | output_parser\n",
    "\n",
    "chain.invoke({\"soccer_player\": \"Ronaldo\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining LECL Chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x0000027EA1E89390>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x0000027EA1EAEA10>, model_name='llama3-70b-8192', groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llamaChatModel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_template(\"Tell me a sentence about {politician}\")\n",
    "\n",
    "chain = prompt | llamaChatModel | output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Neville Chamberlain, the Prime Minister of the United Kingdom, infamously signed the Munich Agreement in 1938, allowing Nazi Germany to annex Czechoslovakia's Sudetenland.\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\"Chamberlain\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combined Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "historian_prompt = ChatPromptTemplate.from_template(\"Was {politician} positive for humanity\")\n",
    "\n",
    "composed_chain = {\"politician\": chain} | historian_prompt | llamaChatModel | output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"What a complex and controversial figure Neville Chamberlain is!\\n\\nWhile Chamberlain's policy of appeasement towards Nazi Germany, particularly with regards to the Munich Agreement in 1938, is widely criticized and considered a grave mistake, it's essential to evaluate his actions in the context of the time and consider both the positive and negative aspects of his premiership.\\n\\n**Negative aspects:**\\n\\n1. **Appeasement policy**: Chamberlain's decision to give in to Hitler's demands, allowing Nazi Germany to annex Czechoslovakia's Sudetenland, is seen as a catastrophic mistake. It emboldened Hitler, who continued to pursue an aggressive expansionist policy, ultimately leading to the outbreak of World War II.\\n2. **Munich Agreement**: The agreement, signed on September 30, 1938, is often viewed as a symbol of Britain's weakness and failure to stand up to Nazi aggression. It allowed Germany to occupy Czechoslovakia, which led to the country's eventual dismemberment.\\n3. **Failure to prepare for war**: Chamberlain's government was slow to rearm and prepare Britain for the possibility of war, leaving the country ill-equipped to respond to the Nazi threat.\\n\\n**Positive aspects:**\\n\\n1. **Buying time**: Chamberlain's appeasement policy, although misguided, did buy Britain some time to prepare for the eventual war. The delay allowed Britain to accelerate its rearmament program, which helped to improve its military readiness.\\n2. **Avoiding immediate war**: Chamberlain's decision to appease Hitler may have prevented an immediate war in 1938, which would have caught Britain and France off guard. This delay allowed Britain to strengthen its alliances and prepare for a longer, more sustained conflict.\\n3. **Domestic achievements**: Chamberlain's government introduced several important domestic reforms, including the Factory Act (1937), which improved working conditions, and the Housing Act (1936), which aimed to address housing shortages.\\n\\n**In conclusion:**\\n\\nWhile Neville Chamberlain's policy of appeasement towards Nazi Germany was a grave mistake, it is essential to consider the complexities of the time and the competing pressures he faced. His actions, although well-intentioned, ultimately contributed to the outbreak of World War II. However, it is also important to acknowledge the positive aspects of his premiership, including the domestic reforms and the time bought to prepare for war.\\n\\nIn terms of his impact on humanity, Chamberlain's legacy is largely negative due to his role in enabling Nazi aggression. However, it is also important to recognize that his experiences and mistakes served as a valuable lesson for future leaders, highlighting the importance of standing up to aggression and protecting human rights and dignity.\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "composed_chain.invoke(\" Chamberlain\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Another Example: A chain inside a chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Une question très facile !\\n\\nLe pays dont François Mitterrand a été le Président de 1981 à 1995 est la France, et la France est située sur le continent européen.\\n\\nDonc, la réponse est : l'Europe.\""
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "prompt1 = ChatPromptTemplate.from_template(\"what is the country {politician} is from?\")\n",
    "prompt2 = ChatPromptTemplate.from_template(\n",
    "    \"what continent is the country {country} in? respond in {language}\"\n",
    ")\n",
    "\n",
    "model = ChatOpenAI()\n",
    "\n",
    "chain1 = prompt1 | model | StrOutputParser()\n",
    "\n",
    "chain2 = (\n",
    "    {\"country\": chain1, \"language\": itemgetter(\"language\")}\n",
    "    | prompt2\n",
    "    | llamaChatModel\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "chain2.invoke({\"politician\": \"Miterrand\", \"language\": \"French\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LCEL chain at work in a typical RAG app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\memor\\anaconda3\\envs\\llmapp\\Lib\\site-packages\\langchain\\hub.py:86: DeprecationWarning: The `langchainhub sdk` is deprecated.\n",
      "Please use the `langsmith sdk` instead:\n",
      "  pip install langsmith\n",
      "Use the `pull_prompt` method.\n",
      "  res_dict = client.pull_repo(owner_repo_commit)\n"
     ]
    }
   ],
   "source": [
    "import bs4\n",
    "from langchain import hub\n",
    "\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "# Picking content from an online github source repository\n",
    "loader = WebBaseLoader(\n",
    "    web_paths=(\"https://lilianweng.github.io/posts/2023-06-23-agent/\",),\n",
    "    bs_kwargs=dict(\n",
    "        parse_only=bs4.SoupStrainer(\n",
    "            class_=(\"post-content\", \"post-title\", \"post-header\")\n",
    "        )\n",
    "    ),\n",
    ")\n",
    "\n",
    "docs = loader.load()\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "\n",
    "splits = text_splitter.split_documents(docs)\n",
    "\n",
    "vectorstore = Chroma.from_documents(documents=splits, embedding=OpenAIEmbeddings())\n",
    "\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "# Automatically created from Langchain HUB online \n",
    "#prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "prompt = hub.pull(\"rlm/rag-prompt-llama\")\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | model     #openai model\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Task Decomposition involves breaking down complicated tasks into smaller and simpler steps. This technique, such as the Chain of Thought (CoT), helps enhance model performance on complex tasks by transforming them into multiple manageable tasks. By decomposing hard tasks, agents can better interpret the model's thinking process and achieve better results.\""
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_chain.invoke(\"What is Task Decomposition?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llmapp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
