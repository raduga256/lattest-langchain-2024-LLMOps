{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ok\n"
     ]
    }
   ],
   "source": [
    "print(\"Ok\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the environment variables from .env file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "# Loading openai key\n",
    "openai_api_key = os.environ[\"OPENAI_API_KEY\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Documentation\n",
    "https://python.langchain.com/docs/integrations/chat/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Completion model\n",
    "\n",
    "from langchain_openai import OpenAI\n",
    "\n",
    "llModel = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interacting with the OpenAI model\n",
    "\n",
    "response = llModel.invoke(\"Tell one fact about the Kennedy Family\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the response\n",
    "\n",
    "print(response) # Completion models can not have conversations with them yet ChatGPT does."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Streaming multiple lines of the response\n",
    "for chunk in llModel.stream():\n",
    "    \"Tell me one fun fact about the Kennedy family. I need a detailed response\"\n",
    "    \n",
    "    print(chunk, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting the configurations of the model -temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "creativeLlModel = OpenAI(temperature=0.9) #creativity parameter\n",
    "\n",
    "response = creativeLlModel.invoke(\"Tell one fun fact about the Kennedy family\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new creative response object and print the response\n",
    "response = creativeLlModel.invoke(\n",
    "    \"Write a short 5 line poem about JFK\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chat Model using ChatOpenAI()\n",
    "It takes two inputs\n",
    "\n",
    "- system role\n",
    "- user prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import openai chatmodel\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# takes two inputs\n",
    "chatModel = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    (\"system\", \"You are an expert historian in the Kennedy Family \"),\n",
    "    (\"human\", \"Tell me one curious thing about JFK \")\n",
    "]\n",
    "response = chatModel.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response)  # Langchain returns response as AIMessage object invoke methods on the \n",
    "    # Langchain's Message object return a text and a list of attachments    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = response.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the meta data like number of tokens in the response, prompt, etc\n",
    "response.response_metadata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking the schema of the response\n",
    "response.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Changing Models\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
    "\n",
    "# write new model object\n",
    "llm  = ChatOpenAI(model=\"gpt-4o-mini\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Old Langchain inputs and import statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    SystemMessage(content=\"You are an expert historian in the Kennedy Family \"),\n",
    "    HumanMessage(content=\"Tell me one curious thing about JFK\")\n",
    "]\n",
    "response = chatModel.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alternatively use Groq API\n",
    "Generate it here: [Groq_api](https://console.groq.com/playground)\n",
    "paste key in the .env file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload the environment to pickup Groq API key\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "_ = load_dotenv(find_dotenv())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the groq api from langchain\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "llamaChatModel = ChatGroq(\n",
    "    model=\"llama3-70b-8192\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load mistral model\n",
    "mistralChatModel = ChatGroq(\n",
    "    model=\"mixtral-8x7b-32768\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pass the two prompts\n",
    "messages = [\n",
    "    (\"system\", \"You are an expert historian in the Kennedy Family \"),\n",
    "    (\"human\", \"Tell me one curious thing about JFK \")\n",
    "]\n",
    "llamaResponse = llamaChatModel.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One curious thing about JFK is that he was a prolific writer and won a Pulitzer Prize for his book \"Profiles in Courage\" in 1957, when he was still a young senator from Massachusetts. What's fascinating is that he didn't actually write the book himself!\n",
      "\n",
      "JFK had the idea for the book, which profiles eight U.S. senators who took courageous stands against public opinion, but he didn't have the time or energy to write it himself. Instead, he hired a team of researchers and writers, including his speechwriter Ted Sorensen, to do the heavy lifting.\n",
      "\n",
      "Sorensen has said that he wrote most of the book, with JFK providing the overall concept and some editing suggestions. Despite this, JFK was awarded the Pulitzer Prize for Biography or Autobiography in 1957, which sparked some controversy at the time.\n",
      "\n",
      "This curious fact speaks to JFK's intellectual curiosity and his ability to inspire and motivate others to help him achieve his goals. It also raises interesting questions about authorship and the role of ghostwriters in shaping public figures' literary legacies.\n"
     ]
    }
   ],
   "source": [
    "print(llamaResponse.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One curious thing about John F. Kennedy (JFK) is that he was the youngest president ever elected in the United States, and he won the election by a very narrow margin. In the 1960 presidential election, JFK received 49.7% of the votes, while his opponent, Richard Nixon, received 49.5% of the votes. This margin of victory was only 0.2%, which is one of the narrowest margins in U.S. presidential election history.\n",
      "\n",
      "Despite his young age and narrow victory, JFK proved to be a popular and influential president. He implemented several significant policies during his time in office, including the establishment of the Peace Corps, the implementation of the Civil Rights Act of 1964, and the establishment of the Alliance for Progress, a program aimed at promoting economic development in Latin America.\n",
      "\n",
      "JFK's presidency was cut short by his assassination on November 22, 1963, but his legacy continues to be celebrated and remembered to this day.\n"
     ]
    }
   ],
   "source": [
    "# Using the mistral model\n",
    "\n",
    "mistralResponse = mistralChatModel.invoke(messages)\n",
    "print(mistralResponse.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llmapp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
